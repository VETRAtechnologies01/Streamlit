{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install openai pandas tqdm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLbV-pEUrmW4",
        "outputId": "8f245dbf-3e92-4a73-d5e6-0bfadea9d763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (0.28.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai) (2.32.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai) (3.11.15)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai) (2025.4.26)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (1.20.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Print actual columns\n",
        "print(\"üîç Columns in CSV:\", df.columns.tolist())\n",
        "\n",
        "# ‚úÖ Auto-detect column name that might contain tweets\n",
        "possible_tweet_columns = [\"tweet\", \"text\", \"Tweet\", \"message\", \"content\"]\n",
        "tweet_col = None\n",
        "for col in df.columns:\n",
        "    if col.strip() in possible_tweet_columns:\n",
        "        tweet_col = col\n",
        "        break\n",
        "\n",
        "if not tweet_col:\n",
        "    raise ValueError(\"CSV must contain a column with tweets. Expected one of: 'tweet', 'text', 'message', etc.\")\n",
        "\n",
        "print(f\"‚úÖ Found tweet column: {tweet_col}\")\n",
        "print(df[tweet_col].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "HdfsCR6fsdIW",
        "outputId": "7e6616ab-71c9-4267-b89d-644039cad491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c73541a78d58>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ‚úÖ Print actual columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"üîç Columns in CSV:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# ‚úÖ Auto-detect column name that might contain tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpossible_tweet_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"tweet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Tweet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"message\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# ‚úÖ Direct API key setup (only for private use)\n",
        "openai.api_key = \"sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
        "\n",
        "# OR use environment method if key is set using os.environ before\n",
        "# openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n"
      ],
      "metadata": {
        "id": "a2PbToi0vF4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "print(openai.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixUBGUD2wJju",
        "outputId": "8a963898-90dd-483f-b85c-cfafe8777a88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1I85UMr0wZYP",
        "outputId": "812ccbe5-fedd-4129-ad44-2b15aa99d5d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.11/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (3.11.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2025.4.26)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.20.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# -------------------------------\n",
        "# ‚úÖ Step 1: Setup OpenAI API Key\n",
        "# -------------------------------\n",
        "# Replace with your actual key ‚Äî keep it secret!\n",
        "openai.api_key = \"sk-your_actual_openai_api_key_here\"\n",
        "\n",
        "# -------------------------------\n",
        "# ‚úÖ Step 2: Load and Unzip Dataset\n",
        "# -------------------------------\n",
        "zip_path = \"/content/Sentiment Analysis Dataset export 2025-06-05 15-15-19.zip\"\n",
        "\n",
        "# Unzip the dataset\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/\")\n",
        "\n",
        "# Detect CSV file\n",
        "csv_path = None\n",
        "for filename in os.listdir(\"/content/\"):\n",
        "    if filename.endswith(\".csv\"):\n",
        "        csv_path = os.path.join(\"/content/\", filename)\n",
        "        break\n",
        "\n",
        "if not csv_path:\n",
        "    raise FileNotFoundError(\"‚ùå No CSV file found inside the ZIP archive.\")\n",
        "\n",
        "# Load CSV\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# -------------------------------\n",
        "# ‚úÖ Step 3: Detect Tweet Column\n",
        "# -------------------------------\n",
        "print(\"üîç Columns in CSV:\", df.columns.tolist())\n",
        "\n",
        "possible_tweet_columns = [\"tweet\", \"text\", \"Tweet\", \"message\", \"content\"]\n",
        "tweet_col = None\n",
        "for col in df.columns:\n",
        "    if col.strip() in possible_tweet_columns:\n",
        "        tweet_col = col\n",
        "        break\n",
        "\n",
        "if not tweet_col:\n",
        "    raise ValueError(\"‚ùå CSV must contain a column with tweets. Expected one of: 'tweet', 'text', 'message', etc.\")\n",
        "\n",
        "print(f\"‚úÖ Found tweet column: '{tweet_col}'\")\n",
        "print(\"üîπ Sample Tweets:\")\n",
        "print(df[tweet_col].dropna().head())\n",
        "\n",
        "# -----------------------------------------\n",
        "# ‚úÖ Step 4: Define LLM Sentiment Analyzer\n",
        "# -----------------------------------------\n",
        "def analyze_sentiment_llm(tweet):\n",
        "    try:\n",
        "        tweet = str(tweet).strip()\n",
        "        if not tweet:\n",
        "            return \"Neutral\"\n",
        "\n",
        "        prompt = f\"\"\"You are a sentiment analysis expert. Classify the sentiment of the following tweet using only one word: Positive, Negative, or Neutral.\n",
        "\n",
        "Tweet: \"{tweet}\"\n",
        "Sentiment:\"\"\"\n",
        "\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",  # You can switch to \"gpt-4\" if you have access\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.0\n",
        "        )\n",
        "        result = response['choices'][0]['message']['content'].strip().capitalize()\n",
        "\n",
        "        # Ensure clean and valid response\n",
        "        if result not in [\"Positive\", \"Negative\", \"Neutral\"]:\n",
        "            return \"Uncertain\"\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error processing tweet:\\n{tweet}\\nException: {e}\")\n",
        "        return \"Error\"\n",
        "\n",
        "# ------------------------------------------------\n",
        "# ‚úÖ Step 5: Run Sentiment Analysis with Progress\n",
        "# ------------------------------------------------\n",
        "tqdm.pandas()\n",
        "df[\"sentiment\"] = df[tweet_col].progress_apply(analyze_sentiment_llm)\n",
        "\n",
        "# ----------------------------------------\n",
        "# ‚úÖ Step 6: Save Results to New CSV File\n",
        "# ----------------------------------------\n",
        "output_path = \"/content/teen_tweet_sentiment_results.csv\"\n",
        "df.to_csv(output_path, index=False)\n",
        "print(f\"‚úÖ Sentiment analysis complete and saved to: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "GG3Mi6ErvuLN",
        "outputId": "4cffcd57-114e-4b6b-bd24-bbc73fb2bfe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Columns in CSV: ['Date', 'App', 'Usage (minutes)', 'Notifications', 'Times Opened']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "‚ùå CSV must contain a column with tweets. Expected one of: 'tweet', 'text', 'message', etc.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-4e15139bdc2e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtweet_col\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚ùå CSV must contain a column with tweets. Expected one of: 'tweet', 'text', 'message', etc.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"‚úÖ Found tweet column: '{tweet_col}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: ‚ùå CSV must contain a column with tweets. Expected one of: 'tweet', 'text', 'message', etc."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# -------------------------------\n",
        "# ‚úÖ Step 1: Setup OpenAI API Key\n",
        "# -------------------------------\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")  # or replace with: openai.api_key = \"your-api-key-here\"\n",
        "\n",
        "# -------------------------------\n",
        "# ‚úÖ Step 2: Load and Unzip Dataset\n",
        "# -------------------------------\n",
        "zip_path = \"/content/Sentiment Analysis Dataset export 2025-06-05 15-15-19.zip\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/\")\n",
        "\n",
        "# Detect CSV file\n",
        "csv_path = None\n",
        "for filename in os.listdir(\"/content/\"):\n",
        "    if filename.endswith(\".csv\"):\n",
        "        csv_path = os.path.join(\"/content/\", filename)\n",
        "        break\n",
        "\n",
        "if not csv_path:\n",
        "    raise FileNotFoundError(\"‚ùå No CSV file found inside the ZIP archive.\")\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# -------------------------------\n",
        "# ‚úÖ Step 3: Detect Tweet Column\n",
        "# -------------------------------\n",
        "print(\"üîç Columns in CSV:\", df.columns.tolist())\n",
        "\n",
        "possible_tweet_columns = [\"tweet\", \"text\", \"Tweet\", \"message\", \"content\"]\n",
        "tweet_col = None\n",
        "for col in df.columns:\n",
        "    if col.strip() in possible_tweet_columns:\n",
        "        tweet_col = col\n",
        "        break\n",
        "\n",
        "if not tweet_col:\n",
        "    raise ValueError(\"‚ùå CSV must contain a column with tweets. Expected one of: 'tweet', 'text', 'message', etc.\")\n",
        "\n",
        "print(f\"‚úÖ Found tweet column: '{tweet_col}'\")\n",
        "print(\"üîπ Sample Tweets:\")\n",
        "print(df[tweet_col].head())\n",
        "\n",
        "# -----------------------------------------\n",
        "# ‚úÖ Step 4: Define LLM Sentiment Analyzer\n",
        "# -----------------------------------------\n",
        "def analyze_sentiment_llm(tweet):\n",
        "    try:\n",
        "        prompt = f\"\"\"\n",
        "You are a sentiment analysis expert. Classify the sentiment of the following tweet using only one word: Positive, Negative, or Neutral.\n",
        "\n",
        "Tweet: \"{tweet}\"\n",
        "Sentiment:\"\"\"\n",
        "\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",  # or use \"gpt-4\" if available\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.0\n",
        "        )\n",
        "        result = response['choices'][0]['message']['content'].strip()\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error processing tweet: {tweet}\\nException: {e}\")\n",
        "        return \"Error\"\n",
        "\n",
        "# ------------------------------------------------\n",
        "# ‚úÖ Step 5: Run Sentiment Analysis with Progress\n",
        "# ------------------------------------------------\n",
        "tqdm.pandas()\n",
        "df[\"sentiment\"] = df[tweet_col].progress_apply(analyze_sentiment_llm)\n",
        "\n",
        "# ----------------------------------------\n",
        "# ‚úÖ Step 6: Save Results to New CSV File\n",
        "# ----------------------------------------\n",
        "output_path = \"/content/teen_tweet_sentiment_results.csv\"\n",
        "df.to_csv(output_path, index=False)\n",
        "print(f\"‚úÖ Sentiment analysis complete and saved to: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "TiqRqOGos9Vq",
        "outputId": "4e23aa1c-99a3-45c2-c6c4-7639f896ded6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Columns in CSV: ['Date', 'App', 'Usage (minutes)', 'Notifications', 'Times Opened']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "‚ùå CSV must contain a column with tweets. Expected one of: 'tweet', 'text', 'message', etc.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-a9a89a008aae>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtweet_col\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚ùå CSV must contain a column with tweets. Expected one of: 'tweet', 'text', 'message', etc.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"‚úÖ Found tweet column: '{tweet_col}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: ‚ùå CSV must contain a column with tweets. Expected one of: 'tweet', 'text', 'message', etc."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0jzzbnnXzU2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üîç Available columns in CSV:\", df.columns.tolist())\n",
        "\n",
        "# Manually specify tweet column if auto-detect fails\n",
        "tweet_col = None\n",
        "possible_tweet_columns = [\"tweet\", \"text\", \"Tweet\", \"message\", \"content\"]\n",
        "for col in df.columns:\n",
        "    if col.strip().lower() in [c.lower() for c in possible_tweet_columns]:\n",
        "        tweet_col = col\n",
        "        break\n",
        "\n",
        "# üîß Manually assign if still not found\n",
        "if not tweet_col:\n",
        "    print(\"‚ö†Ô∏è Auto-detection failed. Please assign tweet_col manually.\")\n",
        "    tweet_col = \"your_actual_column_name_here\"  # üîÅ Replace with real column name from print above\n",
        "\n",
        "# Verify\n",
        "print(f\"‚úÖ Using tweet column: {tweet_col}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMkgK7YdSeO7",
        "outputId": "901d71eb-a3bc-425b-ea71-6e8b86ea19c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Available columns in CSV: ['Date', 'App', 'Usage (minutes)', 'Notifications', 'Times Opened']\n",
            "‚ö†Ô∏è Auto-detection failed. Please assign tweet_col manually.\n",
            "‚úÖ Using tweet column: your_actual_column_name_here\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Auto-fix: Pick longest string column as tweet_col\n",
        "if not tweet_col:\n",
        "    string_cols = df.select_dtypes(include='object')\n",
        "    tweet_col = string_cols.apply(lambda col: col.str.len().mean()).idxmax()\n",
        "    print(f\"‚ö†Ô∏è Auto-selected '{tweet_col}' as tweet column based on text length.\")\n"
      ],
      "metadata": {
        "id": "pUITCLzvSl2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect Tweet Column\n",
        "print(\"üîç Columns in CSV:\", df.columns.tolist())\n",
        "\n",
        "tweet_col = None\n",
        "possible_tweet_columns = [\"tweet\", \"text\", \"Tweet\", \"message\", \"content\"]\n",
        "for col in df.columns:\n",
        "    if col.strip().lower() in [c.lower() for c in possible_tweet_columns]:\n",
        "        tweet_col = col\n",
        "        break\n",
        "\n",
        "if not tweet_col:\n",
        "    print(\"‚ö†Ô∏è Auto-detect failed. Trying fallback method...\")\n",
        "    try:\n",
        "        string_cols = df.select_dtypes(include='object')\n",
        "        tweet_col = string_cols.apply(lambda col: col.str.len().mean()).idxmax()\n",
        "        print(f\"‚úÖ Auto-selected tweet column: '{tweet_col}'\")\n",
        "    except Exception as e:\n",
        "        raise ValueError(\"‚ùå Could not find a valid tweet column. Please check your CSV file.\") from e\n",
        "\n",
        "print(f\"üîπ Sample Tweets:\\n{df[tweet_col].head()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nk20qQ71Su4Q",
        "outputId": "f80a13f3-4941-49c3-aa9c-ff845226d24c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Columns in CSV: ['Date', 'App', 'Usage (minutes)', 'Notifications', 'Times Opened']\n",
            "‚ö†Ô∏è Auto-detect failed. Trying fallback method...\n",
            "‚úÖ Auto-selected tweet column: 'Date'\n",
            "üîπ Sample Tweets:\n",
            "0    2024-08-07\n",
            "1    2024-08-08\n",
            "2    2024-08-26\n",
            "3    2024-08-22\n",
            "4    2024-08-12\n",
            "Name: Date, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ijTqVN2vg-7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "py5fKeRhhR22",
        "outputId": "d3586a77-040b-429b-dccb-ca83211b3856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n"
      ],
      "metadata": {
        "id": "TpEjboQ_hYA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv langchain openai pandas tqdm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WZ1BXiIhcrG",
        "outputId": "d6115ac8-55c5-4093-a454-039e5bc885cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (0.28.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.63)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.43)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.5)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai) (3.11.15)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (1.20.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-community langchain-core langchain openai python-dotenv pandas tqdm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WIHh6J0hvni",
        "outputId": "764627e7-994c-46fc-ebf7-38bdc2f7a567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (0.3.63)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (0.28.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.43)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (4.13.2)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (2.11.5)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.16.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.24 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.9.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain-community\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9N_JZi3i5z6",
        "outputId": "2707106c-ed0a-4d3b-baee-d98ddbc44c33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.63)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.25)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.43)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (2.11.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-openai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvxB4zxfjmu7",
        "outputId": "724387ca-ec1e-442b-a8e5-ecb681677fb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.20-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.64 (from langchain-openai)\n",
            "  Downloading langchain_core-0.3.64-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting openai<2.0.0,>=1.68.2 (from langchain-openai)\n",
            "  Downloading openai-1.84.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Collecting langsmith<0.4,>=0.3.45 (from langchain-core<1.0.0,>=0.3.64->langchain-openai)\n",
            "  Downloading langsmith-0.3.45-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.64->langchain-openai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.64->langchain-openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.64->langchain-openai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.64->langchain-openai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.64->langchain-openai) (4.13.2)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.64->langchain-openai) (2.11.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.64->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.64->langchain-openai) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.64->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.64->langchain-openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.64->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.64->langchain-openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.64->langchain-openai) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.4.0)\n",
            "Downloading langchain_openai-0.3.20-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.64-py3-none-any.whl (438 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m438.1/438.1 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.84.0-py3-none-any.whl (725 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m725.5/725.5 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.3.45-py3-none-any.whl (363 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.0/363.0 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai, langsmith, langchain-core, langchain-openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 0.28.0\n",
            "    Uninstalling openai-0.28.0:\n",
            "      Successfully uninstalled openai-0.28.0\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.3.43\n",
            "    Uninstalling langsmith-0.3.43:\n",
            "      Successfully uninstalled langsmith-0.3.43\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.63\n",
            "    Uninstalling langchain-core-0.3.63:\n",
            "      Successfully uninstalled langchain-core-0.3.63\n",
            "Successfully installed langchain-core-0.3.64 langchain-openai-0.3.20 langsmith-0.3.45 openai-1.84.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n"
      ],
      "metadata": {
        "id": "2bV_2SmjkUXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n"
      ],
      "metadata": {
        "id": "oalYGCb4kfK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain langchain-openai python-dotenv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6n9-ZhPxkm-t",
        "outputId": "bca36aec-9ee3-4ffc-a2db-7dacfbd565c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.20)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.64)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.45)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.5)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.84.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G12Qys8ClIVf",
        "outputId": "d779d7ac-fa79-49c7-9640-9761e257896d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.84.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"OPENAI_API_KEY:\", os.getenv(\"OPENAI_API_KEY\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwKjDfdenVfe",
        "outputId": "f7736552-455f-4c20-d5e9-513057ca3389"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OPENAI_API_KEY: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "import openai\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- Load Keys ---\n",
        "load_dotenv()\n",
        "print(\"OPENAI_API_KEY:\", os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "# Initialize LangChain Chat Model (no openai_api_key param needed)\n",
        "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.5)\n",
        "\n",
        "\n",
        "# --- WhatsApp Chat Extraction ---\n",
        "def extract_whatsapp_messages(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        chat = f.read()\n",
        "    # Regex to capture WhatsApp message lines: date, time, sender, message\n",
        "    pattern = re.compile(r'^\\d{1,2}/\\d{1,2}/\\d{2,4}, \\d{1,2}:\\d{2} [APMapm]{2} - ([^:]+): (.+)$')\n",
        "    messages = []\n",
        "    for line in chat.split(\"\\n\"):\n",
        "        match = pattern.match(line)\n",
        "        if match:\n",
        "            sender, msg = match.groups()\n",
        "            if msg.strip() and \"media omitted\" not in msg.lower():\n",
        "                messages.append(f\"{sender}: {msg}\")\n",
        "    return messages\n",
        "\n",
        "\n",
        "def analyze_chat(messages, n=50):\n",
        "    recent = \"\\n\".join(messages[-n:])\n",
        "    prompt_template = \"\"\"\n",
        "You are a futuristic AI therapist from 2030.\n",
        "\n",
        "Analyze these WhatsApp messages:\n",
        "- Emotional tone (stress, joy, anxiety)\n",
        "- Mental clarity & decision style\n",
        "- Mindset type: proactive, reactive, balanced\n",
        "\n",
        "Recommend:\n",
        "- 3 apps/habits to avoid\n",
        "- 3 uplifting movies and songs\n",
        "- 3 good daily mental health habits\n",
        "\n",
        "Output ONLY in JSON format as:\n",
        "{{\"emotional_tone\": \"...\", \"clarity\": \"...\", \"mindset\": \"...\", \"avoid\": [...], \"recommend\": {{\"movies\": [...], \"songs\": [...]}}, \"habits\": [...] }}\n",
        "\n",
        "Chat:\n",
        "{chat}\n",
        "\"\"\"\n",
        "    prompt = PromptTemplate(input_variables=[\"chat\"], template=prompt_template)\n",
        "    formatted_prompt = prompt.format(chat=recent)\n",
        "\n",
        "    response = llm(formatted_prompt)  # <-- fixed here\n",
        "\n",
        "    try:\n",
        "        result = json.loads(response)\n",
        "        return result\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"‚ö†Ô∏è Failed to parse JSON from chat analysis, raw output:\")\n",
        "        print(response)\n",
        "        return response\n",
        "\n",
        "\n",
        "# --- Screen Time Analysis ---\n",
        "def load_screen_time(csv_path):\n",
        "    return pd.read_csv(csv_path)\n",
        "\n",
        "\n",
        "def analyze_screen_time(df):\n",
        "    readable = df.to_string(index=False)\n",
        "    prompt_template = \"\"\"\n",
        "You are a digital wellness AI.\n",
        "\n",
        "Analyze this screen time data:\n",
        "- Focus vs distraction\n",
        "- Burnout, overuse, addiction\n",
        "- Decision fatigue signs\n",
        "\n",
        "Recommend:\n",
        "- Mental clarity (0-100)\n",
        "- Avoid apps\n",
        "- 3 inspiring movies and calming songs\n",
        "- 3 digital detox habits\n",
        "\n",
        "Output ONLY in JSON format as:\n",
        "{{\"clarity_score\": 0-100, \"fatigue\": \"...\", \"avoid_apps\": [...], \"recommend\": {{\"movies\": [...], \"songs\": [...]}}, \"habits\": [...] }}\n",
        "\n",
        "Screen Time Data:\n",
        "{data}\n",
        "\"\"\"\n",
        "    prompt = PromptTemplate(input_variables=[\"data\"], template=prompt_template)\n",
        "    formatted_prompt = prompt.format(data=readable)\n",
        "\n",
        "    response = llm(formatted_prompt)  # <-- fixed here\n",
        "\n",
        "    try:\n",
        "        result = json.loads(response)\n",
        "        return result\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"‚ö†Ô∏è Failed to parse JSON from screen time analysis, raw output:\")\n",
        "        print(response)\n",
        "        return response\n",
        "\n",
        "\n",
        "# --- Twitter Sentiment Analysis ---\n",
        "def analyze_tweets(df):\n",
        "    print(\"üîç Columns in CSV:\", df.columns.tolist())\n",
        "    tweet_col = None\n",
        "    for col in df.columns:\n",
        "        if col.strip().lower() in [\"tweet\", \"text\", \"message\", \"content\"]:\n",
        "            tweet_col = col\n",
        "            break\n",
        "    if not tweet_col:\n",
        "        string_cols = df.select_dtypes(include='object')\n",
        "        tweet_col = string_cols.apply(lambda c: c.str.len().mean()).idxmax()\n",
        "        print(f\"‚úÖ Auto-selected tweet column: '{tweet_col}'\")\n",
        "\n",
        "    def analyze_sentiment_llm(tweet):\n",
        "        prompt = f\"\"\"\n",
        "You are a sentiment expert. Classify the tweet as one word: Positive, Negative, or Neutral.\n",
        "\n",
        "Tweet: \"{tweet}\"\n",
        "Sentiment:\"\"\"\n",
        "        try:\n",
        "            res = openai.ChatCompletion.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=0.0\n",
        "            )\n",
        "            return res['choices'][0]['message']['content'].strip()\n",
        "        except Exception as e:\n",
        "            print(\"‚ö†Ô∏è Error analyzing tweet sentiment:\", e)\n",
        "            return \"Error\"\n",
        "\n",
        "    tqdm.pandas()\n",
        "    df[\"sentiment\"] = df[tweet_col].progress_apply(analyze_sentiment_llm)\n",
        "    return df\n",
        "\n",
        "\n",
        "# --- Final Synthesis ---\n",
        "def synthesize_report(chat_json, screen_json, sentiment_df):\n",
        "    sentiment_counts = sentiment_df[\"sentiment\"].value_counts().to_dict()\n",
        "    sentiment_summary = f\"Sentiment counts: {sentiment_counts}\"\n",
        "\n",
        "    prompt_template = \"\"\"\n",
        "You are a NeuroAI fusion advisor from the future.\n",
        "\n",
        "Combine these:\n",
        "1. WhatsApp analysis:\n",
        "{chat_json}\n",
        "\n",
        "2. Screen time report:\n",
        "{screen_json}\n",
        "\n",
        "3. Twitter sentiment:\n",
        "{sentiments}\n",
        "\n",
        "Summarize teen mental health:\n",
        "- Mood and stress pattern\n",
        "- Top 3 issues\n",
        "- Mindfulness movie/song list\n",
        "- Futuristic habit suggestions\n",
        "\n",
        "Respond warmly and clearly.\n",
        "\"\"\"\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"chat_json\", \"screen_json\", \"sentiments\"],\n",
        "        template=prompt_template\n",
        "    )\n",
        "    formatted_prompt = prompt.format(\n",
        "        chat_json=json.dumps(chat_json, indent=2) if isinstance(chat_json, dict) else str(chat_json),\n",
        "        screen_json=json.dumps(screen_json, indent=2) if isinstance(screen_json, dict) else str(screen_json),\n",
        "        sentiments=sentiment_summary\n",
        "    )\n",
        "    return llm(formatted_prompt)  # <-- fixed here\n",
        "\n",
        "\n",
        "# --- MAIN PIPELINE ---\n",
        "if __name__ == \"__main__\":\n",
        "    whatsapp_file = \"whatsapp_chat.txt\"\n",
        "    screen_time_file = \"screentime.csv\"\n",
        "    twitter_file = \"teen_tweets.csv\"\n",
        "\n",
        "    try:\n",
        "        # 1. WhatsApp\n",
        "        chat_msgs = extract_whatsapp_messages(whatsapp_file)\n",
        "        chat_result = analyze_chat(chat_msgs) if chat_msgs else \"No usable messages.\"\n",
        "\n",
        "        # 2. Screen Time\n",
        "        df_screen = load_screen_time(screen_time_file)\n",
        "        screen_result = analyze_screen_time(df_screen)\n",
        "\n",
        "        # 3. Twitter Sentiment\n",
        "        df_tweets = pd.read_csv(twitter_file)\n",
        "        sentiment_df = analyze_tweets(df_tweets)\n",
        "\n",
        "        # 4. Synthesis\n",
        "        final_report = synthesize_report(chat_result, screen_result, sentiment_df)\n",
        "        print(\"\\nüß† Final Mental Health Summary:\\n\", final_report)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"‚ùå Pipeline failed:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "UCcLVcPgpCYU",
        "outputId": "672f21d5-2bf2-4203-8ba6-a86a76310ad5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OPENAI_API_KEY: None\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValidationError",
          "evalue": "1 validation error for ChatOpenAI\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'model_name': 'gpt-4', '...ne, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-a08a0e679e79>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Initialize LangChain Chat Model (no openai_api_key param needed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m                         \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                         \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 obj.__init__ = functools.wraps(obj.__init__)(  # type: ignore[misc]\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/load/serializable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;34m\"\"\"\"\"\"\u001b[0m  \u001b[0;31m# noqa: D419\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mvalidated_self\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pydantic_validator__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalidated_self\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             warnings.warn(\n",
            "\u001b[0;31mValidationError\u001b[0m: 1 validation error for ChatOpenAI\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'model_name': 'gpt-4', '...ne, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "import openai\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- Load Keys ---\n",
        "load_dotenv()\n",
        "print(\"OPENAI_API_KEY:\", os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.5)  # No openai_api_key param here\n",
        "\n",
        "\n",
        "\n",
        "# --- WhatsApp Chat Extraction ---\n",
        "def extract_whatsapp_messages(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        chat = f.read()\n",
        "    # Regex to capture WhatsApp message lines: date, time, sender, message\n",
        "    pattern = re.compile(r'^\\d{1,2}/\\d{1,2}/\\d{2,4}, \\d{1,2}:\\d{2} [APMapm]{2} - ([^:]+): (.+)$')\n",
        "    messages = []\n",
        "    for line in chat.split(\"\\n\"):\n",
        "        match = pattern.match(line)\n",
        "        if match:\n",
        "            sender, msg = match.groups()\n",
        "            if msg.strip() and \"media omitted\" not in msg.lower():\n",
        "                messages.append(f\"{sender}: {msg}\")\n",
        "    return messages\n",
        "\n",
        "def analyze_chat(messages, n=50):\n",
        "    recent = \"\\n\".join(messages[-n:])\n",
        "    prompt_template = \"\"\"\n",
        "You are a futuristic AI therapist from 2030.\n",
        "\n",
        "Analyze these WhatsApp messages:\n",
        "- Emotional tone (stress, joy, anxiety)\n",
        "- Mental clarity & decision style\n",
        "- Mindset type: proactive, reactive, balanced\n",
        "\n",
        "Recommend:\n",
        "- 3 apps/habits to avoid\n",
        "- 3 uplifting movies and songs\n",
        "- 3 good daily mental health habits\n",
        "\n",
        "Output ONLY in JSON format as:\n",
        "{{\"emotional_tone\": \"...\", \"clarity\": \"...\", \"mindset\": \"...\", \"avoid\": [...], \"recommend\": {{\"movies\": [...], \"songs\": [...]}}, \"habits\": [...] }}\n",
        "\n",
        "Chat:\n",
        "{chat}\n",
        "\"\"\"\n",
        "    prompt = PromptTemplate(input_variables=[\"chat\"], template=prompt_template)\n",
        "    formatted_prompt = prompt.format(chat=recent)\n",
        "\n",
        "    # Use LangChain's llm.call to get the output text\n",
        "    response = llm.call_as_llm(formatted_prompt)\n",
        "\n",
        "    # Try parsing JSON output\n",
        "    try:\n",
        "        result = json.loads(response)\n",
        "        return result\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"‚ö†Ô∏è Failed to parse JSON from chat analysis, raw output:\")\n",
        "        print(response)\n",
        "        return response\n",
        "\n",
        "# --- Screen Time Analysis ---\n",
        "def load_screen_time(csv_path):\n",
        "    return pd.read_csv(csv_path)\n",
        "\n",
        "def analyze_screen_time(df):\n",
        "    readable = df.to_string(index=False)\n",
        "    prompt_template = \"\"\"\n",
        "You are a digital wellness AI.\n",
        "\n",
        "Analyze this screen time data:\n",
        "- Focus vs distraction\n",
        "- Burnout, overuse, addiction\n",
        "- Decision fatigue signs\n",
        "\n",
        "Recommend:\n",
        "- Mental clarity (0-100)\n",
        "- Avoid apps\n",
        "- 3 inspiring movies and calming songs\n",
        "- 3 digital detox habits\n",
        "\n",
        "Output ONLY in JSON format as:\n",
        "{{\"clarity_score\": 0-100, \"fatigue\": \"...\", \"avoid_apps\": [...], \"recommend\": {{\"movies\": [...], \"songs\": [...]}}, \"habits\": [...] }}\n",
        "\n",
        "Screen Time Data:\n",
        "{data}\n",
        "\"\"\"\n",
        "    prompt = PromptTemplate(input_variables=[\"data\"], template=prompt_template)\n",
        "    formatted_prompt = prompt.format(data=readable)\n",
        "\n",
        "    response = llm.call_as_llm(formatted_prompt)\n",
        "\n",
        "    try:\n",
        "        result = json.loads(response)\n",
        "        return result\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"‚ö†Ô∏è Failed to parse JSON from screen time analysis, raw output:\")\n",
        "        print(response)\n",
        "        return response\n",
        "\n",
        "# --- Twitter Sentiment Analysis ---\n",
        "def analyze_tweets(df):\n",
        "    print(\"üîç Columns in CSV:\", df.columns.tolist())\n",
        "    tweet_col = None\n",
        "    for col in df.columns:\n",
        "        if col.strip().lower() in [\"tweet\", \"text\", \"message\", \"content\"]:\n",
        "            tweet_col = col\n",
        "            break\n",
        "    if not tweet_col:\n",
        "        string_cols = df.select_dtypes(include='object')\n",
        "        tweet_col = string_cols.apply(lambda c: c.str.len().mean()).idxmax()\n",
        "        print(f\"‚úÖ Auto-selected tweet column: '{tweet_col}'\")\n",
        "\n",
        "    def analyze_sentiment_llm(tweet):\n",
        "        prompt = f\"\"\"\n",
        "You are a sentiment expert. Classify the tweet as one word: Positive, Negative, or Neutral.\n",
        "\n",
        "Tweet: \"{tweet}\"\n",
        "Sentiment:\"\"\"\n",
        "        try:\n",
        "            res = openai.ChatCompletion.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=0.0\n",
        "            )\n",
        "            return res['choices'][0]['message']['content'].strip()\n",
        "        except Exception as e:\n",
        "            print(\"‚ö†Ô∏è Error analyzing tweet sentiment:\", e)\n",
        "            return \"Error\"\n",
        "\n",
        "    tqdm.pandas()\n",
        "    df[\"sentiment\"] = df[tweet_col].progress_apply(analyze_sentiment_llm)\n",
        "    return df\n",
        "\n",
        "# --- Final Synthesis ---\n",
        "def synthesize_report(chat_json, screen_json, sentiment_df):\n",
        "    sentiment_counts = sentiment_df[\"sentiment\"].value_counts().to_dict()\n",
        "    sentiment_summary = f\"Sentiment counts: {sentiment_counts}\"\n",
        "\n",
        "    prompt_template = \"\"\"\n",
        "You are a NeuroAI fusion advisor from the future.\n",
        "\n",
        "Combine these:\n",
        "1. WhatsApp analysis:\n",
        "{chat_json}\n",
        "\n",
        "2. Screen time report:\n",
        "{screen_json}\n",
        "\n",
        "3. Twitter sentiment:\n",
        "{sentiments}\n",
        "\n",
        "Summarize teen mental health:\n",
        "- Mood and stress pattern\n",
        "- Top 3 issues\n",
        "- Mindfulness movie/song list\n",
        "- Futuristic habit suggestions\n",
        "\n",
        "Respond warmly and clearly.\n",
        "\"\"\"\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"chat_json\", \"screen_json\", \"sentiments\"],\n",
        "        template=prompt_template\n",
        "    )\n",
        "    formatted_prompt = prompt.format(\n",
        "        chat_json=json.dumps(chat_json, indent=2) if isinstance(chat_json, dict) else str(chat_json),\n",
        "        screen_json=json.dumps(screen_json, indent=2) if isinstance(screen_json, dict) else str(screen_json),\n",
        "        sentiments=sentiment_summary\n",
        "    )\n",
        "    return llm.call_as_llm(formatted_prompt)\n",
        "\n",
        "# --- MAIN PIPELINE ---\n",
        "if __name__ == \"__main__\":\n",
        "    whatsapp_file = \"whatsapp_chat.txt\"\n",
        "    screen_time_file = \"screentime.csv\"\n",
        "    twitter_file = \"teen_tweets.csv\"\n",
        "\n",
        "    try:\n",
        "        # 1. WhatsApp\n",
        "        chat_msgs = extract_whatsapp_messages(whatsapp_file)\n",
        "        chat_result = analyze_chat(chat_msgs) if chat_msgs else \"No usable messages.\"\n",
        "\n",
        "        # 2. Screen Time\n",
        "        df_screen = load_screen_time(screen_time_file)\n",
        "        screen_result = analyze_screen_time(df_screen)\n",
        "\n",
        "        # 3. Twitter Sentiment\n",
        "        df_tweets = pd.read_csv(twitter_file)\n",
        "        sentiment_df = analyze_tweets(df_tweets)\n",
        "\n",
        "        # 4. Synthesis\n",
        "        final_report = synthesize_report(chat_result, screen_result, sentiment_df)\n",
        "        print(\"\\nüß† Final Mental Health Summary:\\n\", final_report)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"‚ùå Pipeline failed:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "iZFXA5ivm50d",
        "outputId": "b93c7bca-243b-412c-dc95-23fecb0a1997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OPENAI_API_KEY: None\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValidationError",
          "evalue": "1 validation error for ChatOpenAI\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'model_name': 'gpt-4', '...ne, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-0e85d8d86290>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# No openai_api_key param here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m                         \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                         \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 obj.__init__ = functools.wraps(obj.__init__)(  # type: ignore[misc]\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/load/serializable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;34m\"\"\"\"\"\"\u001b[0m  \u001b[0;31m# noqa: D419\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mvalidated_self\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pydantic_validator__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalidated_self\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             warnings.warn(\n",
            "\u001b[0;31mValidationError\u001b[0m: 1 validation error for ChatOpenAI\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'model_name': 'gpt-4', '...ne, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "from langchain_openai import ChatOpenAI  # ‚úÖ updated import\n",
        "from langchain.prompts import PromptTemplate\n",
        "import openai\n",
        "from tqdm import tqdm\n",
        "import zipfile\n",
        "\n",
        "# --- Load Keys ---\n",
        "load_dotenv()\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "llm = ChatOpenAI(model=\"gpt-4\", temperature=0.5, openai_api_key=openai.api_key)  # ‚úÖ updated instantiation\n",
        "\n",
        "\n",
        "# --- WhatsApp Chat Extraction ---\n",
        "def extract_whatsapp_messages(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        chat = f.read()\n",
        "    pattern = re.compile(r'^\\d{1,2}/\\d{1,2}/\\d{2,4}, \\d{1,2}:\\d{2} [APMapm]{2} - ([^:]+): (.+)$')\n",
        "    messages = []\n",
        "    for line in chat.split(\"\\n\"):\n",
        "        match = pattern.match(line)\n",
        "        if match:\n",
        "            sender, msg = match.groups()\n",
        "            if msg.strip() and \"media omitted\" not in msg.lower():\n",
        "                messages.append(f\"{sender}: {msg}\")\n",
        "    return messages\n",
        "\n",
        "def analyze_chat(messages, n=50):\n",
        "    recent = \"\\n\".join(messages[-n:])\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"chat\"],\n",
        "        template=\"\"\"\n",
        "You are a futuristic AI therapist from 2030.\n",
        "\n",
        "Analyze these WhatsApp messages:\n",
        "- Emotional tone (stress, joy, anxiety)\n",
        "- Mental clarity & decision style\n",
        "- Mindset type: proactive, reactive, balanced\n",
        "\n",
        "Recommend:\n",
        "- 3 apps/habits to avoid\n",
        "- 3 uplifting movies and songs\n",
        "- 3 good daily mental health habits\n",
        "\n",
        "Output in JSON:\n",
        "{{\"emotional_tone\": \"...\", \"clarity\": \"...\", \"mindset\": \"...\", \"avoid\": [...], \"recommend\": {{\"movies\": [...], \"songs\": [...]}}, \"habits\": [...] }}\n",
        "\n",
        "Chat:\n",
        "{chat}\n",
        "\"\"\"\n",
        "    )\n",
        "    return llm.invoke(prompt.format(chat=recent))\n",
        "\n",
        "# --- Screen Time Analysis ---\n",
        "def load_screen_time(csv_path):\n",
        "    return pd.read_csv(csv_path)\n",
        "\n",
        "def analyze_screen_time(df):\n",
        "    readable = df.to_string(index=False)\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"data\"],\n",
        "        template=\"\"\"\n",
        "You are a digital wellness AI.\n",
        "\n",
        "Analyze this screen time data:\n",
        "- Focus vs distraction\n",
        "- Burnout, overuse, addiction\n",
        "- Decision fatigue signs\n",
        "\n",
        "Recommend:\n",
        "- Mental clarity (0-100)\n",
        "- Avoid apps\n",
        "- 3 inspiring movies and calming songs\n",
        "- 3 digital detox habits\n",
        "\n",
        "Output in JSON:\n",
        "{{\"clarity_score\": 0-100, \"fatigue\": \"...\", \"avoid_apps\": [...], \"recommend\": {{\"movies\": [...], \"songs\": [...]}}, \"habits\": [...] }}\n",
        "\n",
        "Screen Time:\n",
        "{data}\n",
        "\"\"\"\n",
        "    )\n",
        "    return llm.invoke(prompt.format(data=readable))\n",
        "\n",
        "# --- Twitter Sentiment Analysis ---\n",
        "def analyze_tweets(df):\n",
        "    # Try to detect tweet column\n",
        "    print(\"üîç Columns in CSV:\", df.columns.tolist())\n",
        "    tweet_col = None\n",
        "    for col in df.columns:\n",
        "        if col.strip().lower() in [\"tweet\", \"text\", \"message\", \"content\"]:\n",
        "            tweet_col = col\n",
        "            break\n",
        "    if not tweet_col:\n",
        "        string_cols = df.select_dtypes(include='object')\n",
        "        tweet_col = string_cols.apply(lambda c: c.str.len().mean()).idxmax()\n",
        "        print(f\"‚úÖ Auto-selected tweet column: '{tweet_col}'\")\n",
        "\n",
        "    def analyze_sentiment_llm(tweet):\n",
        "        try:\n",
        "            prompt = f\"\"\"\n",
        "You are a sentiment expert. Classify the tweet as one word: Positive, Negative, or Neutral.\n",
        "\n",
        "Tweet: \"{tweet}\"\n",
        "Sentiment:\"\"\"\n",
        "            res = openai.ChatCompletion.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=0.0\n",
        "            )\n",
        "            return res['choices'][0]['message']['content'].strip()\n",
        "        except Exception as e:\n",
        "            print(\"‚ö†Ô∏è\", e)\n",
        "            return \"Error\"\n",
        "\n",
        "    tqdm.pandas()\n",
        "    df[\"sentiment\"] = df[tweet_col].progress_apply(analyze_sentiment_llm)\n",
        "    return df\n",
        "\n",
        "# --- Final Synthesis ---\n",
        "def synthesize_report(chat_json, screen_json, sentiment_df):\n",
        "    sentiment_counts = sentiment_df[\"sentiment\"].value_counts().to_dict()\n",
        "    sentiment_summary = f\"Sentiment counts: {sentiment_counts}\"\n",
        "\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"chat_json\", \"screen_json\", \"sentiments\"],\n",
        "        template=\"\"\"\n",
        "You are a NeuroAI fusion advisor from the future.\n",
        "\n",
        "Combine these:\n",
        "1. WhatsApp analysis:\n",
        "{chat_json}\n",
        "\n",
        "2. Screen time report:\n",
        "{screen_json}\n",
        "\n",
        "3. Twitter sentiment:\n",
        "{sentiments}\n",
        "\n",
        "Summarize teen mental health:\n",
        "- Mood and stress pattern\n",
        "- Top 3 issues\n",
        "- Mindfulness movie/song list\n",
        "- Futuristic habit suggestions\n",
        "\n",
        "Respond warmly and clearly.\n",
        "\"\"\"\n",
        "    )\n",
        "    return llm.invoke(prompt.format(\n",
        "        chat_json=chat_json,\n",
        "        screen_json=screen_json,\n",
        "        sentiments=sentiment_summary\n",
        "    ))\n",
        "\n",
        "# --- MAIN PIPELINE ---\n",
        "if __name__ == \"__main__\":\n",
        "    whatsapp_file = \"whatsapp_chat.txt\"\n",
        "    screen_time_file = \"screentime.csv\"\n",
        "    twitter_file = \"teen_tweets.csv\"\n",
        "\n",
        "    try:\n",
        "        # 1. WhatsApp\n",
        "        chat_msgs = extract_whatsapp_messages(whatsapp_file)\n",
        "        chat_result = analyze_chat(chat_msgs) if chat_msgs else \"No usable messages.\"\n",
        "\n",
        "        # 2. Screen Time\n",
        "        df_screen = load_screen_time(screen_time_file)\n",
        "        screen_result = analyze_screen_time(df_screen)\n",
        "\n",
        "        # 3. Twitter Sentiment\n",
        "        df_tweets = pd.read_csv(twitter_file)\n",
        "        sentiment_df = analyze_tweets(df_tweets)\n",
        "\n",
        "        # 4. Synthesis\n",
        "        final_report = synthesize_report(chat_result, screen_result, sentiment_df)\n",
        "        print(\"\\nüß† Final Mental Health Summary:\\n\", final_report)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"‚ùå Pipeline failed:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "FI1Vj4UCg-iI",
        "outputId": "40465c46-9185-4a0d-a772-68282de812b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'openai' has no attribute 'DefaultHttpxClient'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-3744a14bb6ef>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdotenv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dotenv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m  \u001b[0;31m# ‚úÖ updated import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPromptTemplate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_openai/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAzureChatOpenAI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAzureOpenAIEmbeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOpenAIEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAzureOpenAI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m __all__ = [\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mazure\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAzureChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"ChatOpenAI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"AzureChatOpenAI\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/azure.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSelf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSelf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m from langchain_openai.chat_models._client_utils import (\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0m_get_default_async_httpx_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0m_get_default_httpx_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/_client_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0m_SyncHttpxClientWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDefaultHttpxClient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;34m\"\"\"Borrowed from openai._base_client\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'openai' has no attribute 'DefaultHttpxClient'"
          ]
        }
      ]
    }
  ]
}