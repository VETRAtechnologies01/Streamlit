{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "HPjcAEP2AzJl",
        "outputId": "48f27a09-04f8-4375-a1f7-0fea0afd670e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: using Google CoLab\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SecretNotFoundError",
          "evalue": "Secret OPENAI_API_KEY does not exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSecretNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-2579830666.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# OpenAI Secrets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mCOLAB\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'OPENAI_API_KEY'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Install needed libraries in CoLab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exists'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mSecretNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'access'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mNotebookAccessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSecretNotFoundError\u001b[0m: Secret OPENAI_API_KEY does not exist."
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "    from google.colab import drive, userdata\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False\n",
        "\n",
        "# OpenAI Secrets\n",
        "if COLAB:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Install needed libraries in CoLab\n",
        "if COLAB:\n",
        "    !pip install langchain openai streamlit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "\n",
        "st.write(\"Hello World\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2UUxM8jBzpp",
        "outputId": "7573f248-c20f-450c-ceb6-c2fe3b8b08ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://loca.lt/mytunnelpassword"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vP0gdZRvCHlV",
        "outputId": "b924aaa2-838d-4bc9-b711-32008edd50da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.91.235.33"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "bal9bj9jCjq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D80wIMTNCnEc",
        "outputId": "70d08add-008e-4828-95ae-701bc469750a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K\u001b[1G\u001b[0JNeed to install the following packages:\n",
            "localtunnel@2.0.2\n",
            "Ok to proceed? (y) \u001b[20Gy\n",
            "\n",
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0Kyour url is: https://solid-adults-pull.loca.lt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from my_model import analyze_data  # Your model function\n",
        "\n",
        "input_text = st.text_area(\"Paste your text:\")\n",
        "if st.button(\"Analyze\"):\n",
        "    result = analyze_data(input_text)\n",
        "    st.write(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "fPkOOHIexE_K",
        "outputId": "0ea5e075-3cd6-4dbb-ac83-fee9892f5afa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'my_model'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-7-2619141130.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmy_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0manalyze_data\u001b[0m  \u001b[0;31m# Your model function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_area\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Paste your text:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbutton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Analyze\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'my_model'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# llm_model.py\n",
        "\n",
        "def analyze_data(user_input: str) -> str:\n",
        "    # Replace this with your actual LLM call (OpenAI, GPT, LangChain, etc.)\n",
        "    return f\"LLM Response: {user_input[::-1]}\"  # Dummy reversed text\n"
      ],
      "metadata": {
        "id": "Sa8SVIRnxmUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py\n",
        "import streamlit as st\n",
        "from llm_model import analyze_data  # Import your LLM function\n",
        "\n",
        "# Streamlit UI\n",
        "st.set_page_config(page_title=\"LLM Analyzer\", layout=\"centered\")\n",
        "st.title(\"üîç LLM Text Analyzer\")\n",
        "st.markdown(\"This tool analyzes your input using a custom LLM pipeline.\")\n",
        "\n",
        "# User input\n",
        "user_input = st.text_area(\"‚úèÔ∏è Enter your text here:\", height=200)\n",
        "\n",
        "# Button to analyze\n",
        "if st.button(\"Analyze\"):\n",
        "    if user_input.strip() == \"\":\n",
        "        st.warning(\"Please enter some text.\")\n",
        "    else:\n",
        "        with st.spinner(\"Analyzing...\"):\n",
        "            output = analyze_data(user_input)\n",
        "        st.success(\"Analysis Complete ‚úÖ\")\n",
        "        st.markdown(\"### üîé LLM Output:\")\n",
        "        st.write(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "3Ti0HrwkxmP3",
        "outputId": "8cc74381-eb61-4a92-88e3-968a76940416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'streamlit'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-9-3241372127.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# app.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mllm_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0manalyze_data\u001b[0m  \u001b[0;31m# Import your LLM function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Streamlit UI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'streamlit'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# llm_pipeline.py\n",
        "import pandas as pd\n",
        "\n",
        "def analyze_whatsapp(chat_text: str) -> str:\n",
        "    return f\"üü¢ WhatsApp Analysis: {len(chat_text)} characters\"\n",
        "\n",
        "def analyze_screen_time(df: pd.DataFrame) -> str:\n",
        "    return f\"üì± Screen Time Analysis: {df.shape[0]} rows\"\n",
        "\n",
        "def analyze_twitter(tweet_text: str) -> str:\n",
        "    return f\"üê¶ Twitter Sentiment: Positive (dummy)\"\n"
      ],
      "metadata": {
        "id": "l4Sgfv7GyRWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from llm_pipeline import analyze_whatsapp, analyze_screen_time, analyze_twitter\n",
        "\n",
        "st.set_page_config(page_title=\"Mental Health Analyzer\", layout=\"wide\")\n",
        "\n",
        "st.title(\"üß† Unified Mental Health & Behavior Analyzer\")\n",
        "st.markdown(\"Upload your **WhatsApp chat**, **screen time CSV**, and enter **tweet** to analyze with LLM.\")\n",
        "\n",
        "# --- WhatsApp Upload ---\n",
        "st.header(\"üìÅ WhatsApp Chat Upload\")\n",
        "whatsapp_file = st.file_uploader(\"Upload exported WhatsApp chat (.txt)\", type=\"txt\")\n",
        "\n",
        "if whatsapp_file:\n",
        "    chat_text = whatsapp_file.read().decode(\"utf-8\")\n",
        "    if st.button(\"Analyze WhatsApp Chat\"):\n",
        "        with st.spinner(\"Analyzing WhatsApp...\"):\n",
        "            result = analyze_whatsapp(chat_text)\n",
        "        st.success(result)\n",
        "\n",
        "# --- Screen Time Upload ---\n",
        "st.header(\"üìä Screen Time Upload\")\n",
        "screen_time_file = st.file_uploader(\"Upload screen time CSV\", type=[\"csv\"])\n",
        "\n",
        "if screen_time_file:\n",
        "    df = pd.read_csv(screen_time_file)\n",
        "    st.dataframe(df.head())\n",
        "    if st.button(\"Analyze Screen Time\"):\n",
        "        with st.spinner(\"Analyzing Screen Time...\"):\n",
        "            result = analyze_screen_time(df)\n",
        "        st.success(result)\n",
        "\n",
        "# --- Twitter Sentiment ---\n",
        "st.header(\"üê¶ Twitter Sentiment Analysis\")\n",
        "tweet_text = st.text_area(\"Enter Tweet Text or Twitter User's Tweet:\", height=150)\n",
        "\n",
        "if st.button(\"Analyze Tweet\"):\n",
        "    if tweet_text.strip() == \"\":\n",
        "        st.warning(\"Please enter tweet content.\")\n",
        "    else:\n",
        "        with st.spinner(\"Analyzing Tweet...\"):\n",
        "            result = analyze_twitter(tweet_text)\n",
        "        st.success(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "12Mp4AiuyXlE",
        "outputId": "e7979db7-72ed-483f-df44-46fc194b97cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'streamlit'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-11-3009178220.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# app.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mllm_pipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0manalyze_whatsapp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalyze_screen_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalyze_twitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'streamlit'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# llm_model.py\n",
        "def analyze_data(source: str, text: str) -> str:\n",
        "    if source == \"whatsapp\":\n",
        "        return f\"üü¢ WhatsApp Analysis: {text[:100]}\"\n",
        "    elif source == \"screen_time\":\n",
        "        return f\"üì± Screen Time Analysis: {text[:100]}\"\n",
        "    elif source == \"twitter\":\n",
        "        return f\"üê¶ Twitter Sentiment: {text[:100]}\"\n",
        "    return \"‚ùå Unknown source\"\n"
      ],
      "metadata": {
        "id": "QYH_TZlOyiFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from llm_pipeline import analyze_whatsapp, analyze_screen_time, analyze_twitter\n",
        "\n",
        "st.set_page_config(page_title=\"üß† Mental Health LLM Analyzer\", layout=\"wide\")\n",
        "\n",
        "st.title(\"üß† Mental Health & Behavior Analyzer with LLM\")\n",
        "st.markdown(\"Upload your **WhatsApp chat (.txt)**, **screen time CSV**, or enter **tweet text** to analyze using your LLM model.\")\n",
        "\n",
        "# --- WhatsApp Chat Upload ---\n",
        "st.subheader(\"üìÅ WhatsApp Chat (.txt)\")\n",
        "whatsapp_file = st.file_uploader(\"Upload WhatsApp chat file\", type=\"txt\")\n",
        "if whatsapp_file:\n",
        "    chat_text = whatsapp_file.read().decode(\"utf-8\")\n",
        "    if st.button(\"Analyze WhatsApp Chat\"):\n",
        "        with st.spinner(\"Analyzing...\"):\n",
        "            result = analyze_whatsapp(chat_text)\n",
        "        st.success(\"‚úÖ Analysis Complete\")\n",
        "        st.text_area(\"WhatsApp LLM Output:\", result, height=200)\n",
        "\n",
        "# --- Screen Time CSV Upload ---\n",
        "st.subheader(\"üìä Mobile Screen Time CSV\")\n",
        "screen_file = st.file_uploader(\"Upload Screen Time CSV\", type=\"csv\")\n",
        "if screen_file:\n",
        "    df = pd.read_csv(screen_file)\n",
        "    st.dataframe(df.head())\n",
        "    if st.button(\"Analyze Screen Time\"):\n",
        "        with st.spinner(\"Analyzing screen time...\"):\n",
        "            result = analyze_screen_time(df)\n",
        "        st.success(\"‚úÖ Analysis Complete\")\n",
        "        st.text_area(\"Screen Time LLM Output:\", result, height=200)\n",
        "\n",
        "# --- Twitter Sentiment ---\n",
        "st.subheader(\"üê¶ Twitter Sentiment Input\")\n",
        "tweet_text = st.text_area(\"Enter tweet or post text:\", height=150)\n",
        "if st.button(\"Analyze Tweet Sentiment\"):\n",
        "    if tweet_text.strip() == \"\":\n",
        "        st.warning(\"‚ö†Ô∏è Please enter a tweet or text.\")\n",
        "    else:\n",
        "        with st.spinner(\"Analyzing tweet sentiment...\"):\n",
        "            result = analyze_twitter(tweet_text)\n",
        "        st.success(\"‚úÖ Analysis Complete\")\n",
        "        st.text_area(\"Tweet Sentiment LLM Output:\", result, height=200)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "cKIdTg_wy4vG",
        "outputId": "880f45f3-435a-4878-b808-be447c33506d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'streamlit'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-13-1784528523.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# app.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mllm_pipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0manalyze_whatsapp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalyze_screen_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalyze_twitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'streamlit'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from llm_pipeline import analyze_whatsapp, analyze_screen_time, analyze_twitter\n",
        "\n",
        "# Page configuration\n",
        "st.set_page_config(page_title=\"üß† Mental Health LLM Analyzer\", layout=\"wide\")\n",
        "\n",
        "# App title\n",
        "st.title(\"üß† Mental Health & Behavior Analyzer\")\n",
        "st.markdown(\"\"\"\n",
        "Upload your **WhatsApp chat (.txt)**, **screen time CSV**, or enter **tweet text** to analyze using your custom LLM model.\n",
        "\"\"\")\n",
        "\n",
        "# --- WhatsApp Chat Analysis ---\n",
        "st.header(\"üìÅ WhatsApp Chat (.txt)\")\n",
        "whatsapp_file = st.file_uploader(\"Upload exported WhatsApp chat file\", type=\"txt\")\n",
        "\n",
        "if whatsapp_file:\n",
        "    chat_text = whatsapp_file.read().decode(\"utf-8\", errors=\"ignore\")\n",
        "    if st.button(\"üîç Analyze WhatsApp Chat\"):\n",
        "        with st.spinner(\"Analyzing WhatsApp chat using LLM...\"):\n",
        "            whatsapp_result = analyze_whatsapp(chat_text)\n",
        "        st.success(\"‚úÖ WhatsApp Analysis Complete\")\n",
        "        st.text_area(\"üìù WhatsApp LLM Output\", whatsapp_result, height=250)\n",
        "\n",
        "# --- Screen Time CSV Analysis ---\n",
        "st.header(\"üìä Mobile Screen Time CSV\")\n",
        "screen_file = st.file_uploader(\"Upload screen time CSV\", type=\"csv\")\n",
        "\n",
        "if screen_file:\n",
        "    try:\n",
        "        df = pd.read_csv(screen_file)\n",
        "        st.subheader(\"Preview of Uploaded Screen Time Data\")\n",
        "        st.dataframe(df.head())\n",
        "        if st.button(\"üìà Analyze Screen Time\"):\n",
        "            with st.spinner(\"Analyzing screen time with LLM...\"):\n",
        "                screen_result = analyze_screen_time(df)\n",
        "            st.success(\"‚úÖ Screen Time Analysis Complete\")\n",
        "            st.text_area(\"üìù Screen Time LLM Output\", screen_result, height=250)\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error reading CSV file: {e}\")\n",
        "\n",
        "# --- Twitter Sentiment Analysis ---\n",
        "st.header(\"üê¶ Twitter Sentiment\")\n",
        "tweet_text = st.text_area(\"Enter tweet or post text below:\", height=150)\n",
        "\n",
        "if st.button(\"üß† Analyze Tweet Sentiment\"):\n",
        "    if tweet_text.strip() == \"\":\n",
        "        st.warning(\"‚ö†Ô∏è Please enter a tweet or text.\")\n",
        "    else:\n",
        "        with st.spinner(\"Analyzing tweet sentiment...\"):\n",
        "            twitter_result = analyze_twitter(tweet_text)\n",
        "        st.success(\"‚úÖ Tweet Sentiment Analysis Complete\")\n",
        "        st.text_area(\"üìù Twitter Sentiment LLM Output\", twitter_result, height=250)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "fo__F98BzcIE",
        "outputId": "fda1c2d6-7230-45ca-a5e5-c159d0c19fe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'llm_pipeline'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-21-3995991020.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mllm_pipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0manalyze_whatsapp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalyze_screen_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalyze_twitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Page configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llm_pipeline'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5duHmlWI0lx4",
        "outputId": "b7a6c4b9-62f6-4e47-bb06-bd4e87d4e398"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.47.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.47.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.7.14)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.47.0-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.47.0 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# llm_pipeline.py\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# WhatsApp chat analysis\n",
        "def analyze_whatsapp(chat_text: str) -> str:\n",
        "    return f\"üü¢ WhatsApp Analysis:\\nFirst 100 characters:\\n{chat_text[:100]}\"\n",
        "\n",
        "# Screen time analysis\n",
        "def analyze_screen_time(df: pd.DataFrame) -> str:\n",
        "    return f\"üì± Screen Time Analysis:\\nRows: {df.shape[0]}, Columns: {df.columns.tolist()}\"\n",
        "\n",
        "# Twitter sentiment analysis\n",
        "def analyze_twitter(tweet_text: str) -> str:\n",
        "    return f\"üê¶ Twitter Sentiment:\\nText: '{tweet_text}'\\nPredicted: Positive\"\n"
      ],
      "metadata": {
        "id": "QZ1nh2yb07eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from llm_pipeline import analyze_whatsapp, analyze_screen_time, analyze_twitter\n",
        "\n",
        "st.set_page_config(page_title=\"üß† Mental Health LLM Analyzer\", layout=\"wide\")\n",
        "\n",
        "st.title(\"üß† Mental Health & Behavior Analyzer\")\n",
        "st.markdown(\"\"\"\n",
        "Upload your **WhatsApp chat (.txt)**, **screen time CSV**, or enter **tweet text** to analyze using your custom LLM model.\n",
        "\"\"\")\n",
        "\n",
        "# --- WhatsApp Chat Analysis ---\n",
        "st.header(\"üìÅ WhatsApp Chat (.txt)\")\n",
        "whatsapp_file = st.file_uploader(\"Upload exported WhatsApp chat file\", type=\"txt\")\n",
        "if whatsapp_file:\n",
        "    chat_text = whatsapp_file.read().decode(\"utf-8\", errors=\"ignore\")\n",
        "    if st.button(\"üîç Analyze WhatsApp Chat\"):\n",
        "        with st.spinner(\"Analyzing...\"):\n",
        "            result = analyze_whatsapp(chat_text)\n",
        "        st.success(\"‚úÖ Done\")\n",
        "        st.text_area(\"üìù WhatsApp LLM Output\", result, height=250)\n",
        "\n",
        "# --- Screen Time CSV Analysis ---\n",
        "st.header(\"üìä Screen Time CSV\")\n",
        "screen_file = st.file_uploader(\"Upload screen time CSV\", type=\"csv\")\n",
        "if screen_file:\n",
        "    df = pd.read_csv(screen_file)\n",
        "    st.dataframe(df.head())\n",
        "    if st.button(\"üìà Analyze Screen Time\"):\n",
        "        with st.spinner(\"Analyzing...\"):\n",
        "            result = analyze_screen_time(df)\n",
        "        st.success(\"‚úÖ Done\")\n",
        "        st.text_area(\"üìù Screen Time LLM Output\", result, height=250)\n",
        "\n",
        "# --- Twitter Sentiment Analysis ---\n",
        "st.header(\"üê¶ Twitter Sentiment\")\n",
        "tweet_text = st.text_area(\"Enter tweet or post text below:\", height=150)\n",
        "if st.button(\"üß† Analyze Tweet\"):\n",
        "    if tweet_text.strip() == \"\":\n",
        "        st.warning(\"‚ö†Ô∏è Enter a tweet or sentence.\")\n",
        "    else:\n",
        "        with st.spinner(\"Analyzing...\"):\n",
        "            result = analyze_twitter(tweet_text)\n",
        "        st.success(\"‚úÖ Done\")\n",
        "        st.text_area(\"üìù Twitter Sentiment LLM Output\", result, height=250)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "MTPfYP0K0-wc",
        "outputId": "3e01f731-a3c8-4069-f545-16140ffa6a57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'llm_pipeline'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-23-843403651.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mllm_pipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0manalyze_whatsapp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalyze_screen_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalyze_twitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_page_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_title\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"üß† Mental Health LLM Analyzer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"wide\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llm_pipeline'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from llm_pipeline import analyze_whatsapp, analyze_screen_time, analyze_twitter\n",
        "\n",
        "st.set_page_config(page_title=\"üß† Mental Health LLM Analyzer\", layout=\"wide\")\n",
        "\n",
        "st.title(\"üß† Mental Health & Behavior Analyzer\")\n",
        "st.markdown(\"\"\"\n",
        "Upload your **WhatsApp chat (.txt)**, **screen time CSV**, or enter **tweet text** to analyze using your custom LLM model.\n",
        "\"\"\")\n",
        "\n",
        "# --- WhatsApp Chat Analysis ---\n",
        "st.header(\"üìÅ WhatsApp Chat (.txt)\")\n",
        "whatsapp_file = st.file_uploader(\"Upload exported WhatsApp chat file\", type=\"txt\")\n",
        "\n",
        "if whatsapp_file:\n",
        "    chat_text = whatsapp_file.read().decode(\"utf-8\", errors=\"ignore\")\n",
        "    if st.button(\"üîç Analyze WhatsApp Chat\"):\n",
        "        with st.spinner(\"Analyzing WhatsApp chat...\"):\n",
        "            result = analyze_whatsapp(chat_text)\n",
        "        st.success(\"‚úÖ WhatsApp Chat Analysis Done\")\n",
        "        st.text_area(\"üìù WhatsApp LLM Output\", result, height=250)\n",
        "\n",
        "# --- Screen Time CSV Analysis ---\n",
        "st.header(\"üìä Screen Time CSV\")\n",
        "screen_file = st.file_uploader(\"Upload screen time CSV\", type=\"csv\")\n",
        "\n",
        "if screen_file:\n",
        "    try:\n",
        "        df = pd.read_csv(screen_file)\n",
        "        st.subheader(\"üìã Preview of Screen Time Data\")\n",
        "        st.dataframe(df.head())\n",
        "        if st.button(\"üìà Analyze Screen Time\"):\n",
        "            with st.spinner(\"Analyzing screen time...\"):\n",
        "                result = analyze_screen_time(df)\n",
        "            st.success(\"‚úÖ Screen Time Analysis Done\")\n",
        "            st.text_area(\"üìù Screen Time LLM Output\", result, height=250)\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error reading CSV: {e}\")\n",
        "\n",
        "# --- Twitter Sentiment Analysis ---\n",
        "st.header(\"üê¶ Twitter Sentiment\")\n",
        "tweet_text = st.text_area(\"Enter tweet or post text below:\", height=150)\n",
        "\n",
        "if st.button(\"üß† Analyze Tweet\"):\n",
        "    if not tweet_text.strip():\n",
        "        st.warning(\"‚ö†Ô∏è Please enter a tweet.\")\n",
        "    else:\n",
        "        with st.spinner(\"Analyzing tweet sentiment...\"):\n",
        "            result = analyze_twitter(tweet_text)\n",
        "        st.success(\"‚úÖ Tweet Sentiment Analysis Done\")\n",
        "        st.text_area(\"üìù Twitter Sentiment LLM Output\", result, height=250)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "y1qrHtle1bCs",
        "outputId": "977f0c2f-1bc9-4abf-987b-6b98b1169ce3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'llm_pipeline'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-26-2426348231.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mllm_pipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0manalyze_whatsapp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalyze_screen_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalyze_twitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_page_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_title\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"üß† Mental Health LLM Analyzer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"wide\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llm_pipeline'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# llm_pipeline.py\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def analyze_whatsapp(chat_text: str) -> str:\n",
        "    return f\"üü¢ WhatsApp Chat Analysis:\\nTotal characters: {len(chat_text)}\\nPreview: {chat_text[:100]}\"\n",
        "\n",
        "def analyze_screen_time(df: pd.DataFrame) -> str:\n",
        "    return f\"üì± Screen Time Analysis:\\nRows: {df.shape[0]}, Columns: {list(df.columns)}\"\n",
        "\n",
        "def analyze_twitter(tweet_text: str) -> str:\n",
        "    return f\"üê¶ Twitter Sentiment:\\nTweet: '{tweet_text}'\\nSentiment: Positive\"\n"
      ],
      "metadata": {
        "id": "3vTnh3aJ1tTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from llm_pipeline import analyze_whatsapp, analyze_screen_time, analyze_twitter\n",
        "\n",
        "st.set_page_config(page_title=\"üß† Mental Health LLM Analyzer\", layout=\"wide\")\n",
        "\n",
        "st.title(\"üß† Mental Health & Behavior Analyzer\")\n",
        "st.markdown(\"\"\"\n",
        "Upload your **WhatsApp chat (.txt)**, **screen time CSV**, or enter **tweet text** to analyze using your custom LLM model.\n",
        "\"\"\")\n",
        "\n",
        "# --- WhatsApp Chat Analysis ---\n",
        "st.header(\"üìÅ WhatsApp Chat (.txt)\")\n",
        "whatsapp_file = st.file_uploader(\"Upload exported WhatsApp chat file\", type=\"txt\")\n",
        "\n",
        "if whatsapp_file:\n",
        "    chat_text = whatsapp_file.read().decode(\"utf-8\", errors=\"ignore\")\n",
        "    if st.button(\"üîç Analyze WhatsApp Chat\"):\n",
        "        with st.spinner(\"Analyzing WhatsApp chat...\"):\n",
        "            result = analyze_whatsapp(chat_text)\n",
        "        st.success(\"‚úÖ WhatsApp Chat Analysis Done\")\n",
        "        st.text_area(\"üìù WhatsApp LLM Output\", result, height=250)\n",
        "\n",
        "# --- Screen Time CSV Analysis ---\n",
        "st.header(\"üìä Screen Time CSV\")\n",
        "screen_file = st.file_uploader(\"Upload screen time CSV\", type=\"csv\")\n",
        "\n",
        "if screen_file:\n",
        "    try:\n",
        "        df = pd.read_csv(screen_file)\n",
        "        st.subheader(\"üìã Preview of Screen Time Data\")\n",
        "        st.dataframe(df.head())\n",
        "        if st.button(\"üìà Analyze Screen Time\"):\n",
        "            with st.spinner(\"Analyzing screen time...\"):\n",
        "                result = analyze_screen_time(df)\n",
        "            st.success(\"‚úÖ Screen Time Analysis Done\")\n",
        "            st.text_area(\"üìù Screen Time LLM Output\", result, height=250)\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error reading CSV: {e}\")\n",
        "\n",
        "# --- Twitter Sentiment Analysis ---\n",
        "st.header(\"üê¶ Twitter Sentiment\")\n",
        "tweet_text = st.text_area(\"Enter tweet or post text below:\", height=150)\n",
        "\n",
        "if st.button(\"üß† Analyze Tweet\"):\n",
        "    if not tweet_text.strip():\n",
        "        st.warning(\"‚ö†Ô∏è Please enter a tweet.\")\n",
        "    else:\n",
        "        with st.spinner(\"Analyzing tweet sentiment...\"):\n",
        "            result = analyze_twitter(tweet_text)\n",
        "        st.success(\"‚úÖ Tweet Sentiment Analysis Done\")\n",
        "        st.text_area(\"üìù Twitter Sentiment LLM Output\", result, height=250)# llm_pipeline.py\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def analyze_whatsapp(chat_text: str) -> str:\n",
        "    # Simulated analysis; replace with your actual LLM logic\n",
        "    return f\"üü¢ WhatsApp Chat Analysis:\\nTotal characters: {len(chat_text)}\\nFirst 100 chars: {chat_text[:100]}\"\n",
        "\n",
        "def analyze_screen_time(df: pd.DataFrame) -> str:\n",
        "    # Simulated analysis; replace with your actual LLM logic\n",
        "    return f\"üì± Screen Time Analysis:\\nApps found: {df['App'].nunique() if 'App' in df.columns else 'N/A'}\\nRows: {df.shape[0]}\"\n",
        "\n",
        "def analyze_twitter(tweet_text: str) -> str:\n",
        "    # Simulated sentiment; replace with your actual LLM model\n",
        "    return f\"üê¶ Twitter Sentiment Analysis:\\nTweet: {tweet_text}\\nPredicted Sentiment: Positive\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "jW8C0Uow14Kz",
        "outputId": "ad18fb8a-9f2c-4125-b1e6-e9f161a5941c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'llm_pipeline'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-30-3452984622.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mllm_pipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0manalyze_whatsapp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalyze_screen_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalyze_twitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_page_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_title\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"üß† Mental Health LLM Analyzer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"wide\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llm_pipeline'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from llm_pipeline import analyze_whatsapp, analyze_screen_time, analyze_twitter\n",
        "\n",
        "st.set_page_config(page_title=\"üß† Mental Health LLM Analyzer\", layout=\"wide\")\n",
        "\n",
        "st.title(\"üß† Mental Health & Behavior Analyzer\")\n",
        "st.markdown(\"\"\"\n",
        "Upload your **WhatsApp chat (.txt)**, **screen time CSV**, or enter **tweet text** to analyze using your custom LLM model.\n",
        "\"\"\")\n",
        "\n",
        "# --- WhatsApp Chat Analysis ---\n",
        "st.header(\"üìÅ WhatsApp Chat (.txt)\")\n",
        "whatsapp_file = st.file_uploader(\"Upload exported WhatsApp chat file\", type=\"txt\")\n",
        "\n",
        "if whatsapp_file:\n",
        "    chat_text = whatsapp_file.read().decode(\"utf-8\", errors=\"ignore\")\n",
        "    if st.button(\"üîç Analyze WhatsApp Chat\"):\n",
        "        with st.spinner(\"Analyzing WhatsApp chat...\"):\n",
        "            result = analyze_whatsapp(chat_text)\n",
        "        st.success(\"‚úÖ WhatsApp Chat Analysis Done\")\n",
        "        st.text_area(\"üìù WhatsApp LLM Output\", result, height=250)\n",
        "\n",
        "# --- Screen Time CSV Analysis ---\n",
        "st.header(\"üìä Screen Time CSV\")\n",
        "screen_file = st.file_uploader(\"Upload screen time CSV\", type=\"csv\")\n",
        "\n",
        "if screen_file:\n",
        "    try:\n",
        "        df = pd.read_csv(screen_file)\n",
        "        st.subheader(\"üìã Preview of Screen Time Data\")\n",
        "        st.dataframe(df.head())\n",
        "        if st.button(\"üìà Analyze Screen Time\"):\n",
        "            with st.spinner(\"Analyzing screen time...\"):\n",
        "                result = analyze_screen_time(df)\n",
        "            st.success(\"‚úÖ Screen Time Analysis Done\")\n",
        "            st.text_area(\"üìù Screen Time LLM Output\", result, height=250)\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error reading CSV: {e}\")\n",
        "\n",
        "# --- Twitter Sentiment Analysis ---\n",
        "st.header(\"üê¶ Twitter Sentiment\")\n",
        "tweet_text = st.text_area(\"Enter tweet or post text below:\", height=150)\n",
        "\n",
        "if st.button(\"üß† Analyze Tweet\"):\n",
        "    if not tweet_text.strip():\n",
        "        st.warning(\"‚ö†Ô∏è Please enter a tweet.\")\n",
        "    else:\n",
        "        with st.spinner(\"Analyzing tweet sentiment...\"):\n",
        "            result = analyze_twitter(tweet_text)\n",
        "        st.success(\"‚úÖ Tweet Sentiment Analysis Done\")\n",
        "        st.text_area(\"üìù Twitter Sentiment LLM Output\", result, height=250)\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from llm_pipeline import analyze_whatsapp, analyze_screen_time, analyze_twitter\n",
        "\n",
        "st.set_page_config(page_title=\"üß† Mental Health LLM Analyzer\", layout=\"wide\")\n",
        "\n",
        "st.title(\"üß† Mental Health & Behavior Analyzer\")\n",
        "st.markdown(\"\"\"\n",
        "Upload your **WhatsApp chat (.txt)**, **screen time CSV**, or enter **tweet text** to analyze using your custom LLM model.\n",
        "\"\"\")\n",
        "\n",
        "# --- WhatsApp Chat Analysis ---\n",
        "st.header(\"üìÅ WhatsApp Chat (.txt)\")\n",
        "whatsapp_file = st.file_uploader(\"Upload exported WhatsApp chat file\", type=\"txt\")\n",
        "\n",
        "if whatsapp_file:\n",
        "    chat_text = whatsapp_file.read().decode(\"utf-8\", errors=\"ignore\")\n",
        "    if st.button(\"üîç Analyze WhatsApp Chat\"):\n",
        "        with st.spinner(\"Analyzing WhatsApp chat...\"):\n",
        "            result = analyze_whatsapp(chat_text)\n",
        "        st.success(\"‚úÖ WhatsApp Chat Analysis Done\")\n",
        "        st.text_area(\"üìù WhatsApp LLM Output\", result, height=250)\n",
        "\n",
        "# --- Screen Time CSV Analysis ---\n",
        "st.header(\"üìä Screen Time CSV\")\n",
        "screen_file = st.file_uploader(\"Upload screen time CSV\", type=\"csv\")\n",
        "\n",
        "if screen_file:\n",
        "    try:\n",
        "        df = pd.read_csv(screen_file)\n",
        "        st.subheader(\"üìã Preview of Screen Time Data\")\n",
        "        st.dataframe(df.head())\n",
        "        if st.button(\"üìà Analyze Screen Time\"):\n",
        "            with st.spinner(\"Analyzing screen time...\"):\n",
        "                result = analyze_screen_time(df)\n",
        "            st.success(\"‚úÖ Screen Time Analysis Done\")\n",
        "            st.text_area(\"üìù Screen Time LLM Output\", result, height=250)\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error reading CSV: {e}\")\n",
        "\n",
        "# --- Twitter Sentiment Analysis ---\n",
        "st.header(\"üê¶ Twitter Sentiment\")\n",
        "tweet_text = st.text_area(\"Enter tweet or post text below:\", height=150)\n",
        "\n",
        "if st.button(\"üß† Analyze Tweet\"):\n",
        "    if not tweet_text.strip():\n",
        "        st.warning(\"‚ö†Ô∏è Please enter a tweet.\")\n",
        "    else:\n",
        "        with st.spinner(\"Analyzing tweet sentiment...\"):\n",
        "            result = analyze_twitter(tweet_text)\n",
        "        st.success(\"‚úÖ Tweet Sentiment Analysis Done\")\n",
        "        st.text_area(\"üìù Twitter Sentiment LLM Output\", result, height=250)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "b1eJo2_l2Twt",
        "outputId": "17b7bf03-3614-43a4-a959-407db7f75627"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'llm_pipeline'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-29-3702927928.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mllm_pipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0manalyze_whatsapp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalyze_screen_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalyze_twitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_page_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_title\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"üß† Mental Health LLM Analyzer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"wide\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llm_pipeline'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# llm_pipeline.py\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def analyze_whatsapp(chat_text: str) -> str:\n",
        "    # Simulated LLM analysis\n",
        "    return (\n",
        "        f\"üü¢ WhatsApp Chat Analysis:\\n\"\n",
        "        f\"Total characters: {len(chat_text)}\\n\"\n",
        "        f\"First 100 characters:\\n{chat_text[:100]}\"\n",
        "    )\n",
        "\n",
        "def analyze_screen_time(df: pd.DataFrame) -> str:\n",
        "    # Simulated LLM analysis\n",
        "    if 'App' in df.columns:\n",
        "        app_count = df['App'].nunique()\n",
        "    else:\n",
        "        app_count = 'N/A'\n",
        "    return (\n",
        "        f\"üì± Screen Time Analysis:\\n\"\n",
        "        f\"Total rows: {df.shape[0]}\\n\"\n",
        "        f\"Unique apps used: {app_count}\"\n",
        "    )\n",
        "\n",
        "def analyze_twitter(tweet_text: str) -> str:\n",
        "    # Simulated sentiment prediction\n",
        "    return (\n",
        "        f\"üê¶ Twitter Sentiment Analysis:\\n\"\n",
        "        f\"Tweet: \\\"{tweet_text}\\\"\\n\"\n",
        "        f\"Predicted Sentiment: Positive\"\n",
        "    )\n"
      ],
      "metadata": {
        "id": "L8G5JuBl20fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from llm_pipeline import analyze_whatsapp, analyze_screen_time, analyze_twitter\n",
        "\n",
        "# The rest of your working Streamlit code...\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "GaSpML1q3TSV",
        "outputId": "b4e0c26c-3667-4b21-f571-f669cfdb2123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'llm_pipeline'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-34-3198818693.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mllm_pipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0manalyze_whatsapp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalyze_screen_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalyze_twitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# The rest of your working Streamlit code...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llm_pipeline'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from llm_pipeline import analyze_whatsapp, analyze_screen_time, analyze_twitter\n",
        "\n",
        "# Page setup\n",
        "st.set_page_config(page_title=\"üß† Mental Health LLM Analyzer\", layout=\"wide\")\n",
        "\n",
        "st.title(\"üß† Mental Health & Behavior Analyzer\")\n",
        "st.markdown(\"\"\"\n",
        "Upload your **WhatsApp chat (.txt)**, **screen time CSV**, or enter **tweet text** to analyze using your custom LLM model.\n",
        "\"\"\")\n",
        "\n",
        "# --- WhatsApp Chat Analysis ---\n",
        "st.header(\"üìÅ WhatsApp Chat (.txt)\")\n",
        "whatsapp_file = st.file_uploader(\"Upload exported WhatsApp chat file\", type=\"txt\")\n",
        "\n",
        "if whatsapp_file:\n",
        "    chat_text = whatsapp_file.read().decode(\"utf-8\", errors=\"ignore\")\n",
        "    if st.button(\"üîç Analyze WhatsApp Chat\"):\n",
        "        with st.spinner(\"Analyzing WhatsApp chat...\"):\n",
        "            result = analyze_whatsapp(chat_text)\n",
        "        st.success(\"‚úÖ WhatsApp Chat Analysis Done\")\n",
        "        st.text_area(\"üìù WhatsApp LLM Output\", result, height=250)\n",
        "\n",
        "# --- Screen Time CSV Analysis ---\n",
        "st.header(\"üìä Screen Time CSV\")\n",
        "screen_file = st.file_uploader(\"Upload screen time CSV\", type=\"csv\")\n",
        "\n",
        "if screen_file:\n",
        "    try:\n",
        "        df = pd.read_csv(screen_file)\n",
        "        st.subheader(\"üìã Preview of Screen Time Data\")\n",
        "        st.dataframe(df.head())\n",
        "        if st.button(\"üìà Analyze Screen Time\"):\n",
        "            with st.spinner(\"Analyzing screen time...\"):\n",
        "                result = analyze_screen_time(df)\n",
        "            st.success(\"‚úÖ Screen Time Analysis Done\")\n",
        "            st.text_area(\"üìù Screen Time LLM Output\", result, height=250)\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error reading CSV: {e}\")\n",
        "\n",
        "# --- Twitter Sentiment Analysis ---\n",
        "st.header(\"üê¶ Twitter Sentiment\")\n",
        "tweet_text = st.text_area(\"Enter tweet or post text below:\", height=150)\n",
        "\n",
        "if st.button(\"üß† Analyze Tweet\"):\n",
        "    if not tweet_text.strip():\n",
        "        st.warning(\"‚ö†Ô∏è Please enter a tweet.\")\n",
        "    else:\n",
        "        with st.spinner(\"Analyzing tweet sentiment...\"):\n",
        "            result = analyze_twitter(tweet_text)\n",
        "        st.success(\"‚úÖ Tweet Sentiment Analysis Done\")\n",
        "        st.text_area(\"üìù Twitter Sentiment LLM Output\", result, height=250)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "VZdI5Fwb251d",
        "outputId": "7195d1bb-676e-436b-de22-9c5bce340e5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'llm_pipeline'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-38-2362057684.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mllm_pipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0manalyze_whatsapp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalyze_screen_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalyze_twitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Page setup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llm_pipeline'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "\n",
        "# --- LLM backend functions ---\n",
        "def analyze_whatsapp(chat_text: str) -> str:\n",
        "    return f\"üü¢ WhatsApp Analysis:\\nTotal characters: {len(chat_text)}\\nPreview: {chat_text[:100]}\"\n",
        "\n",
        "def analyze_screen_time(df: pd.DataFrame) -> str:\n",
        "    if 'App' in df.columns:\n",
        "        apps = df['App'].nunique()\n",
        "    else:\n",
        "        apps = 'Unknown'\n",
        "    return f\"üì± Screen Time Analysis:\\nRows: {len(df)}\\nUnique apps: {apps}\"\n",
        "\n",
        "def analyze_twitter(tweet_text: str) -> str:\n",
        "    return f\"üê¶ Twitter Sentiment:\\nTweet: {tweet_text}\\nSentiment: Positive\"\n",
        "\n",
        "# --- Streamlit frontend ---\n",
        "st.set_page_config(page_title=\"üß† Mental Health LLM Analyzer\", layout=\"wide\")\n",
        "\n",
        "st.title(\"üß† Mental Health & Behavior Analyzer\")\n",
        "\n",
        "# WhatsApp\n",
        "st.header(\"üìÅ WhatsApp Chat (.txt)\")\n",
        "whatsapp_file = st.file_uploader(\"Upload exported WhatsApp chat file\", type=\"txt\")\n",
        "if whatsapp_file:\n",
        "    chat_text = whatsapp_file.read().decode(\"utf-8\", errors=\"ignore\")\n",
        "    if st.button(\"üîç Analyze WhatsApp Chat\"):\n",
        "        with st.spinner(\"Analyzing WhatsApp chat...\"):\n",
        "            result = analyze_whatsapp(chat_text)\n",
        "        st.success(\"‚úÖ WhatsApp Chat Analysis Done\")\n",
        "        st.text_area(\"üìù WhatsApp LLM Output\", result, height=250)\n",
        "\n",
        "# Screen Time\n",
        "st.header(\"üìä Screen Time CSV\")\n",
        "screen_file = st.file_uploader(\"Upload screen time CSV\", type=\"csv\")\n",
        "if screen_file:\n",
        "    df = pd.read_csv(screen_file)\n",
        "    st.dataframe(df.head())\n",
        "    if st.button(\"üìà Analyze Screen Time\"):\n",
        "        with st.spinner(\"Analyzing screen time...\"):\n",
        "            result = analyze_screen_time(df)\n",
        "        st.success(\"‚úÖ Screen Time Analysis Done\")\n",
        "        st.text_area(\"üìù Screen Time LLM Output\", result, height=250)\n",
        "\n",
        "# Twitter\n",
        "st.header(\"üê¶ Twitter Sentiment\")\n",
        "tweet_text = st.text_area(\"Enter tweet text below:\", height=150)\n",
        "if st.button(\"üß† Analyze Tweet\"):\n",
        "    if not tweet_text.strip():\n",
        "        st.warning(\"‚ö†Ô∏è Please enter a tweet.\")\n",
        "    else:\n",
        "        with st.spinner(\"Analyzing tweet sentiment...\"):\n",
        "            result = analyze_twitter(tweet_text)\n",
        "        st.success(\"‚úÖ Tweet Sentiment Analysis Done\")\n",
        "        st.text_area(\"üìù Twitter Sentiment LLM Output\", result, height=250)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGhqCoE_3eG1",
        "outputId": "be89f275-c5e0-4c6a-8259-d3d2f440d0db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-16 20:12:56.495 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.497 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.498 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.499 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.501 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.503 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.503 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.504 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.505 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.506 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.507 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.507 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.508 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.509 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.510 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.511 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.512 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.513 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.513 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.514 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.515 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.515 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.517 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.517 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.518 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.519 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.520 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.521 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.522 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.522 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.523 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.524 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.525 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.526 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.526 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.527 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.528 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-16 20:12:56.528 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    }
  ]
}